{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mitsuba as mi\n",
    "import drjit as dr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random \n",
    "import imageio\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_path = os.path.join('', 'scenes') \n",
    "results_spatio_path = os.path.join('','results_spatio') \n",
    "mi.set_variant('scalar_rgb')\n",
    "texture_path = os.path.join(scene_path,'textures')\n",
    "\n",
    "tokki = os.path.join(scene_path,'meshes/bunny.ply')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam1 = mi.load_dict({\n",
    "'type': 'perspective',\n",
    "'fov': 45, #24.6 mm\n",
    "'to_world': mi.ScalarTransform4f.look_at(\n",
    "    origin=[0.03, 0, -0.7],  # increase the z-coordinate to move the camera farther away\n",
    "    target=[0.03, 1, -15],\n",
    "    up=[0, 0, 1]\n",
    "),\n",
    "'film2': {\n",
    "    'type': 'hdrfilm',\n",
    "    'width': 360,\n",
    "    'height': 360,\n",
    "}\n",
    "# 'distortion': [0, 0, 0, 0, 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cgi, os\n",
    "files = os.listdir('dir/graycode_pattern/')\n",
    "\n",
    "for f in files:\n",
    "    s = \"dir/graycode_pattern/\"\n",
    "    s = s + f\n",
    "    scene1 = mi.load_dict({\n",
    "        'type':'scene',\n",
    "        'integrator': {'type': 'direct'},\n",
    "        'light': {\n",
    "            'type': 'projector',\n",
    "            'irradiance': {\n",
    "                'type': 'bitmap',\n",
    "                'filename': s, \n",
    "            },\n",
    "            'fov': 45,\n",
    "            'to_world': mi.ScalarTransform4f.look_at(\n",
    "                origin=[-0.03, 0.1, -0.7],\n",
    "                target=[-0.03, -0.1, -15],\n",
    "                up=[0, 0, 1]\n",
    "            )\n",
    "            },\n",
    "        'tok':{\n",
    "            'type': 'ply',\n",
    "            'filename': tokki,\n",
    "            'to_world': mi.ScalarTransform4f.translate([0, 0, -1]),\n",
    "            'bsdf': {\n",
    "                'type': 'diffuse',\n",
    "                'reflectance': {'type': 'rgb', 'value': [0.1, 0.2, 0.3]},\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    image = mi.render(scene=scene1, sensor=cam1, spp=64)\n",
    "    image = np.clip(image * 1000, 0, 1000).astype(np.uint8)\n",
    "    st = \"./results/resultfar_\" + f\n",
    "    # Save the image as a PNG file using imageio\n",
    "    imageio.imwrite(st, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function Rodrigues:\n",
      "\n",
      "Rodrigues(...)\n",
      "    Rodrigues(src[, dst[, jacobian]]) -> dst, jacobian\n",
      "    .   @brief Converts a rotation matrix to a rotation vector or vice versa.\n",
      "    .   \n",
      "    .   @param src Input rotation vector (3x1 or 1x3) or rotation matrix (3x3).\n",
      "    .   @param dst Output rotation matrix (3x3) or rotation vector (3x1 or 1x3), respectively.\n",
      "    .   @param jacobian Optional output Jacobian matrix, 3x9 or 9x3, which is a matrix of partial\n",
      "    .   derivatives of the output array components with respect to the input array components.\n",
      "    .   \n",
      "    .   \\f[\\begin{array}{l} \\theta \\leftarrow norm(r) \\\\ r  \\leftarrow r/ \\theta \\\\ R =  \\cos(\\theta) I + (1- \\cos{\\theta} ) r r^T +  \\sin(\\theta) \\vecthreethree{0}{-r_z}{r_y}{r_z}{0}{-r_x}{-r_y}{r_x}{0} \\end{array}\\f]\n",
      "    .   \n",
      "    .   Inverse transformation can be also done easily, since\n",
      "    .   \n",
      "    .   \\f[\\sin ( \\theta ) \\vecthreethree{0}{-r_z}{r_y}{r_z}{0}{-r_x}{-r_y}{r_x}{0} = \\frac{R - R^T}{2}\\f]\n",
      "    .   \n",
      "    .   A rotation vector is a convenient and most compact representation of a rotation matrix (since any\n",
      "    .   rotation matrix has just 3 degrees of freedom). The representation is used in the global 3D geometry\n",
      "    .   optimization procedures like @ref calibrateCamera, @ref stereoCalibrate, or @ref solvePnP .\n",
      "    .   \n",
      "    .   @note More information about the computation of the derivative of a 3D rotation matrix with respect to its exponential coordinate\n",
      "    .   can be found in:\n",
      "    .       - A Compact Formula for the Derivative of a 3-D Rotation in Exponential Coordinates, Guillermo Gallego, Anthony J. Yezzi @cite Gallego2014ACF\n",
      "    .   \n",
      "    .   @note Useful information on SE(3) and Lie Groups can be found in:\n",
      "    .       - A tutorial on SE(3) transformation parameterizations and on-manifold optimization, Jose-Luis Blanco @cite blanco2010tutorial\n",
      "    .       - Lie Groups for 2D and 3D Transformation, Ethan Eade @cite Eade17\n",
      "    .       - A micro Lie theory for state estimation in robotics, Joan Sol&#224;, J&#233;r&#233;mie Deray, Dinesh Atchuthan @cite Sol2018AML\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.Rodrigues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.19851213e+05, 0.00000000e+00, 7.84005194e+04],\n",
       "       [0.00000000e+00, 1.19851213e+05, 7.84005194e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the rotation matrix from the camera transformation matrix\n",
    "cam_transform = mi.ScalarTransform4f.look_at(\n",
    "    origin=[0.03, 0, -0.7],\n",
    "    target=[0.03, 1, -15],\n",
    "    up=[0, 0, 1]\n",
    ")\n",
    "cam_to_world = np.array(cam_transform.matrix)\n",
    "cam_rot_vec, _ = cv2.Rodrigues(cam_to_world[:3, :3])\n",
    "cam_rot_mat = np.array(cam_rot_vec)\n",
    "\n",
    "# Define the proj_dist and proj_int matrices\n",
    "proj_dist = np.zeros((4, 1))\n",
    "\n",
    "proj =  mi.ScalarTransform4f.look_at(\n",
    "            origin=[-0.03, 0.1, -0.7],\n",
    "            target=[-0.03, -0.1, -15],\n",
    "            up=[0, 0, 1]\n",
    "        )\n",
    "\n",
    "proj_int = np.array([[360/(2*np.tan(45*np.pi/360)) , 0, 360/2],\n",
    "                     [0, 360/(2*np.tan(45*np.pi/360)), 360/2],\n",
    "                     [0, 0, 1]])\n",
    "# Compute the cam_proj_rmat matrix\n",
    "# cam_proj_rmat = np.dot(proj_int, np.hstack((cam_rot_mat, -np.dot(cam_rot_mat, cam_to_world[:3, 3].reshape(-1,1)))))\n",
    "\n",
    "proj_int = np.array([[434.55844123,   0.        , 180.        ],\n",
    "       [  0.        , 434.55844123, 180.        ],\n",
    "       [  0.        ,   0.        ,   1.        ]])\n",
    "\n",
    "cam_int = np.array([[275.8, 0, 180], [0, 275.8, 180], [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "\n",
    "cam_proj_rmat = np.dot(proj_int, cam_to_world[:3, :3])\n",
    "cam_proj_rmat = np.dot(proj_int, cam_int)\n",
    "\n",
    "cam_proj_rmat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1796576605.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    K = [127.279   0       179.5         0    127.279   179.5         0       0         1 ]\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[434.55844123,   0.        , 180.        ],\n",
       "       [  0.        , 434.55844123, 180.        ],\n",
       "       [  0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_int = np.array([[360/(2*np.tan(45*np.pi/360)) , 0, 360/2],\n",
    "                     [0, 360/(2*np.tan(45*np.pi/360)), 360/2],\n",
    "                     [0, 0, 1]])\n",
    "proj_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[512.19512195,   0.        , 180.        ],\n",
       "       [  0.        , 512.19512195, 180.        ],\n",
       "       [  0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# focal_length_px = 360 * (35 / 24.6)  # convert 35mm focal length to pixels\n",
    "# fx = fy = focal_length_px\n",
    "# cx = cy = 360 / 2  # assuming the principal point is at the center of the image\n",
    "# s = 0  # assuming no skew\n",
    "# cam_int = np.array([[fx, s, cx], [0, fy, cy], [0, 0, 1]])\n",
    "# cam_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64941598,  0.64941598, -1.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = 360\n",
    "v = 360\n",
    "point = np.array([u, v, 1])\n",
    "cam_int = np.array([[275.8, 0, 180], [0, 275.8, 180], [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "\n",
    "cam_proj_tvec = -np.linalg.inv(cam_proj_rmat) @ np.linalg.inv(cam_int) @ proj_int @ point\n",
    "cam_proj_tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
